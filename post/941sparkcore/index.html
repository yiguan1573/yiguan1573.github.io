<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">

    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="referrer" content="never">
	
    
    <meta property="og:site_name" content="亿观的博客">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://yiguan1573.gitee.io//img/01.jpg">
    <meta property="twitter:image" content="https://yiguan1573.gitee.io//img/01.jpg" />
    

    
    <meta name="title" content="1、SparkCore（Spark）" />
    <meta property="og:title" content="1、SparkCore（Spark）" />
    <meta property="twitter:title" content="1、SparkCore（Spark）" />
    

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    <meta property="twitter:description" content="" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>1、SparkCore（Spark）-yiguan1573</title>

    <link rel="canonical" href="/post/941sparkcore/">

    <link rel="stylesheet" href="/css/iDisqus.min.css"/>
	
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    
    <link rel="stylesheet" href="/css/syntax.css">
    
    
    <link rel="stylesheet" href="/css/zanshang.css">
    
    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    
    

    
    
    <script src="/js/jquery.min.js"></script>
    
    
    <script src="/js/bootstrap.min.js"></script>
    
    
    <script src="/js/hux-blog.min.js"></script>

    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/docco.min.css">
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    

</head>



<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">亿观的博客</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">主页</a>
                    </li>
                    
                        
                        <li>
                            <a href="/categories/%E5%AD%A6%E4%B9%A0">学习</a>
                        </li>
                        
                    
                    
		    
                        <li><a href="/#">图书</a></li>
                    
                        <li><a href="/#">关于</a></li>
                    

                    
		    <li>
                        <a href="/search">搜索 <img src="/img/search.png" height="15" style="cursor: pointer;" alt="Search"></a>
		    </li>
                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('http://ww1.sinaimg.cn/large/006QQPIfly1gh0wuilf8mj31hc0u0kh8.jpg')
    }
</style>
<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/spark" title="Spark">
                            Spark
                        </a>
                        
                    </div>
                    <h1>1、SparkCore（Spark）</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        Posted by 
                        
                                 &#34;亿观&#34;
                         
                        on 
                        Thursday, December 2, 2021
                        
                        
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <header>
                    <h2></h2>
                </header>
                <nav id="TableOfContents">
  <ul>
    <li><a href="#spark概述">Spark概述</a>
      <ul>
        <li><a href="#spark-是什么">Spark 是什么</a></li>
        <li><a href="#spark-and-hadoop">Spark and Hadoop</a></li>
        <li><a href="#spark-or-hadoop">Spark or Hadoop</a></li>
        <li><a href="#spark-核心模块">Spark 核心模块</a></li>
      </ul>
    </li>
    <li><a href="#spark-快速上手">Spark 快速上手</a>
      <ul>
        <li><a href="#创建maven项目">创建Maven项目</a></li>
      </ul>
    </li>
    <li><a href="#spark-运行环境">Spark 运行环境</a>
      <ul>
        <li><a href="#local-模式">Local 模式</a></li>
        <li><a href="#standalone-模式">Standalone 模式</a></li>
        <li><a href="#yarn-模式">Yarn 模式</a></li>
        <li><a href="#部署模式对比">部署模式对比</a></li>
        <li><a href="#端口号">端口号</a></li>
      </ul>
    </li>
    <li><a href="#spark运行架构">Spark运行架构</a>
      <ul>
        <li><a href="#运行架构">运行架构</a></li>
        <li><a href="#核心组件">核心组件</a></li>
        <li><a href="#核心概念">核心概念</a></li>
        <li><a href="#提交流程">提交流程</a></li>
      </ul>
    </li>
  </ul>
</nav>
                
                <h2 id="spark概述">Spark概述</h2>
<h3 id="spark-是什么">Spark 是什么</h3>
<ul>
<li><strong>Spark 是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。</strong></li>
</ul>
<h3 id="spark-and-hadoop">Spark and Hadoop</h3>
<ul>
<li>
<p><strong>首先从时间节点上来看:</strong></p>
<ul>
<li>Hadoop
<ul>
<li>2006 年 1 月，Doug Cutting 加入Yahoo，领导Hadoop 的开发</li>
<li>2008 年 1 月，Hadoop 成为 Apache 顶级项目</li>
<li>2011 年 1.0 正式发布</li>
<li>2012 年 3 月稳定版发布</li>
<li>2013 年 10 月发布 2.X (Yarn)版本</li>
</ul>
</li>
<li>Spark
<ul>
<li>2009 年，Spark 诞生于伯克利大学的AMPLab 实验室</li>
<li>2010 年，伯克利大学正式开源了 Spark 项目</li>
<li>2013 年 6 月，Spark 成为了 Apache 基金会下的项目</li>
<li>2014 年 2 月，Spark 以飞快的速度成为了 Apache 的顶级项目</li>
<li>2015 年至今，Spark 变得愈发火爆，大量的国内公司开始重点部署或者使用 Spark</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>从功能上来看:</strong></p>
<ul>
<li>
<p>Hadoop</p>
<ul>
<li>Hadoop 是由 java 语言编写的，在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架</li>
<li>作为 Hadoop 分布式文件系统，HDFS 处于 Hadoop 生态圈的最下层，存储着所有的数据， 支持着 Hadoop 的所有服务。 它的理论基础源于 Google 的TheGoogleFileSystem 这篇论文，它是GFS 的开源实现。</li>
<li>MapReduce 是一种编程模型，Hadoop 根据 Google 的 MapReduce 论文将其实现， 作为 Hadoop 的分布式计算模型，是 Hadoop 的核心。基于这个框架，分布式并行程序的编写变得异常简单。综合了 HDFS 的分布式存储和 MapReduce 的分布式计算，Hadoop 在处理海量数据时，性能横向扩展变得非常容易。</li>
<li>HBase 是对 Google 的 Bigtable 的开源实现，但又和 Bigtable 存在许多不同之处。HBase 是一个基于HDFS 的分布式数据库，擅长实时地随机读/写超大规模数据集。它也是 Hadoop 非常重要的组件。</li>
</ul>
</li>
<li>
<p>Spark</p>
<ul>
<li>
<p>Spark 是一种由 Scala 语言开发的快速、通用、可扩展的大数据分析引擎</p>
</li>
<li>
<p>Spark Core 中提供了 Spark 最基础与最核心的功能</p>
</li>
<li>
<p>Spark SQL 是Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用SQL 或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。</p>
</li>
<li>
<p>Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>由上面的信息可以获知，Spark 出现的时间相对较晚，并且主要功能主要是用于数据计算， 所以其实 Spark 一直被认为是Hadoop 框架的升级版。</p>
</li>
</ul>
<h3 id="spark-or-hadoop">Spark or Hadoop</h3>
<ul>
<li>
<p><strong>Hadoop 的 MR 框架和Spark 框架都是数据处理框架，那么我们在使用时如何选择呢？</strong></p>
<ul>
<li><strong>Hadoop在设计时考虑为一次性计算，将计算的结果存储在磁盘中；而Spark将计算的结果放到内存中方便下一次的计算。</strong></li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx494z1lyoj319o0iyjzp.jpg" alt="QQ截图20211206174121.png"></p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4957rs12j31ba0b8dky.jpg" alt="QQ截图20211206174149.png"></p>
<ul>
<li>Hadoop MapReduce 由于其设计初衷并不是为了满足循环迭代式数据流处理，因此在多并行运行的数据可复用场景（如：机器学习、图挖掘算法、交互式数据挖掘算法）中存在诸多计算效率等问题。所以 Spark 应运而生，Spark 就是在传统的MapReduce 计算框架的基础上，利用其计算过程的优化，从而大大加快了数据分析、挖掘的运行和读写速度，并将计算单元缩小到更适合并行计算和重复使用的RDD 计算模型。</li>
<li>机器学习中 ALS、凸优化梯度下降等。这些都需要基于数据集或者数据集的衍生数据反复查询反复操作。MR 这种模式不太合适，即使多 MR 串行处理，性能和时间也是一个问题。数据的共享依赖于磁盘。另外一种是交互式数据挖掘，MR 显然不擅长。而Spark 所基于的 scala 语言恰恰擅长函数的处理。</li>
<li>Spark 是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），提供了比MapReduce 丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。</li>
<li><strong>Spark 和Hadoop 的根本差异是多个作业之间的数据通信问题 : Spark 多个作业之间数据通信是基于内存，而 Hadoop 是基于磁盘。</strong></li>
<li>Spark Task 的启动时间快。Spark 采用 fork 线程的方式，而 Hadoop 采用创建新的进程的方式。</li>
<li>Spark 只有在 shuffle 的时候将数据写入磁盘，而 Hadoop 中多个 MR 作业之间的数据交互都要依赖于磁盘交互</li>
<li>Spark 的缓存机制比HDFS 的缓存机制高效。</li>
</ul>
</li>
<li>
<p>经过上面的比较，我们可以看出在绝大多数的数据计算场景中，Spark 确实会比 MapReduce 更有优势。但是Spark 是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致 Job 执行失败，此时，MapReduce 其实是一个更好的选择，所以 Spark 并不能完全替代 MR。</p>
</li>
</ul>
<h3 id="spark-核心模块">Spark 核心模块</h3>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx49cv8b8jj30o909nwhf.jpg" alt="QQ截图20211206174930.png"></p>
<ul>
<li>
<p>Spark Core 中提供了 Spark 最基础与最核心的功能，Spark 其他的功能如：Spark SQL， Spark Streaming，GraphX, MLlib 都是在 Spark Core 的基础上进行扩展的</p>
</li>
<li>
<p>Spark SQL 是Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用 SQL或者Apache Hive 版本的 SQL 方言（HQL）来查询数据。</p>
</li>
<li>
<p>Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</p>
</li>
<li>
<p>MLlib 是 Spark 提供的一个机器学习算法库。MLlib 不仅提供了模型评估、数据导入等额外的功能，还提供了一些更底层的机器学习原语。</p>
</li>
<li>
<p>GraphX 是 Spark 面向图计算提供的框架与算法库。</p>
</li>
</ul>
<h2 id="spark-快速上手">Spark 快速上手</h2>
<h3 id="创建maven项目">创建Maven项目</h3>
<ul>
<li>
<p>Scala环境</p>
<ul>
<li>首先配置Scala环境变量，其次安装idea插件，详情查看scala笔记</li>
</ul>
</li>
<li>
<p>增加依赖关系</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#f92672">&lt;dependencies</span><span style="color:#f92672">&gt;</span>
     <span style="color:#f92672">&lt;dependency</span><span style="color:#f92672">&gt;</span>
         <span style="color:#f92672">&lt;groupId</span><span style="color:#f92672">&gt;</span>org.apache.spark<span style="color:#f92672">&lt;/groupId&gt;</span>
         <span style="color:#f92672">&lt;artifactId</span><span style="color:#f92672">&gt;</span>spark-core_2.12<span style="color:#f92672">&lt;/artifactId&gt;</span>
         <span style="color:#f92672">&lt;version</span><span style="color:#f92672">&gt;</span>3.0.0<span style="color:#f92672">&lt;/version&gt;</span>
     <span style="color:#f92672">&lt;/dependency&gt;</span>
<span style="color:#f92672">&lt;/dependencies&gt;</span>
<span style="color:#f92672">&lt;build</span><span style="color:#f92672">&gt;</span>
     <span style="color:#f92672">&lt;plugins</span><span style="color:#f92672">&gt;</span>
         <span style="color:#75715e">&lt;!--</span><span style="color:#75715e"> 该插件用于将 Scala 代码编译成 class 文件 </span><span style="color:#75715e">--&gt;</span>
           
         <span style="color:#f92672">&lt;plugin</span><span style="color:#f92672">&gt;</span>
             <span style="color:#f92672">&lt;groupId</span><span style="color:#f92672">&gt;</span>net.alchim31.maven<span style="color:#f92672">&lt;/groupId&gt;</span>
             <span style="color:#f92672">&lt;artifactId</span><span style="color:#f92672">&gt;</span>scala-maven-plugin<span style="color:#f92672">&lt;/artifactId&gt;</span>
             <span style="color:#f92672">&lt;version</span><span style="color:#f92672">&gt;</span>3.2.2<span style="color:#f92672">&lt;/version&gt;</span>
             <span style="color:#f92672">&lt;executions</span><span style="color:#f92672">&gt;</span>
                 <span style="color:#f92672">&lt;execution</span><span style="color:#f92672">&gt;</span>
                     <span style="color:#75715e">&lt;!--</span><span style="color:#75715e"> 声明绑定到 maven 的 compile 阶段 </span><span style="color:#75715e">--&gt;</span>
                       
                     <span style="color:#f92672">&lt;goals</span><span style="color:#f92672">&gt;</span>
                        <span style="color:#f92672">&lt;goal</span><span style="color:#f92672">&gt;</span>testCompile<span style="color:#f92672">&lt;/goal&gt;</span>
                     <span style="color:#f92672">&lt;/goals&gt;</span>
                 <span style="color:#f92672">&lt;/execution&gt;</span>
             <span style="color:#f92672">&lt;/executions&gt;</span>
         <span style="color:#f92672">&lt;/plugin&gt;</span>
         <span style="color:#f92672">&lt;plugin</span><span style="color:#f92672">&gt;</span>
             <span style="color:#f92672">&lt;groupId</span><span style="color:#f92672">&gt;</span>org.apache.maven.plugins<span style="color:#f92672">&lt;/groupId&gt;</span>
             <span style="color:#f92672">&lt;artifactId</span><span style="color:#f92672">&gt;</span>maven-assembly-plugin<span style="color:#f92672">&lt;/artifactId&gt;</span>
             <span style="color:#f92672">&lt;version</span><span style="color:#f92672">&gt;</span>3.1.0<span style="color:#f92672">&lt;/version&gt;</span>
             <span style="color:#f92672">&lt;configuration</span><span style="color:#f92672">&gt;</span>
                 <span style="color:#f92672">&lt;descriptorRefs</span><span style="color:#f92672">&gt;</span>
                  <span style="color:#f92672">&lt;descriptorRef</span><span style="color:#f92672">&gt;</span>jar-with-dependencies<span style="color:#f92672">&lt;/descriptorRef&gt;</span>
                 <span style="color:#f92672">&lt;/descriptorRefs&gt;</span>
             <span style="color:#f92672">&lt;/configuration&gt;</span>
             <span style="color:#f92672">&lt;executions</span><span style="color:#f92672">&gt;</span>
                 <span style="color:#f92672">&lt;execution</span><span style="color:#f92672">&gt;</span>
                     <span style="color:#f92672">&lt;id</span><span style="color:#f92672">&gt;</span>make-assembly<span style="color:#f92672">&lt;/id&gt;</span>
                     <span style="color:#f92672">&lt;phase</span><span style="color:#f92672">&gt;</span>package<span style="color:#f92672">&lt;/phase&gt;</span>
                     <span style="color:#f92672">&lt;goals</span><span style="color:#f92672">&gt;</span>
                      <span style="color:#f92672">&lt;goal</span><span style="color:#f92672">&gt;</span>single<span style="color:#f92672">&lt;/goal&gt;</span>
                     <span style="color:#f92672">&lt;/goals&gt;</span>
                 <span style="color:#f92672">&lt;/execution&gt;</span>
             <span style="color:#f92672">&lt;/executions&gt;</span>
         <span style="color:#f92672">&lt;/plugin&gt;</span>
     <span style="color:#f92672">&lt;/plugins&gt;</span>
<span style="color:#f92672">&lt;/build&gt;</span>
</code></pre></div></li>
<li>
<p>WordCount</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 创建 Spark 运行配置对象
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> sparkConf <span style="color:#66d9ef">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">SparkConf</span><span style="color:#f92672">(</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>setMaster<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;local[*]&#34;</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>setAppName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;WordCount&#34;</span><span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 创建 Spark 上下文环境对象（连接对象）
</span><span style="color:#75715e"></span>      
<span style="color:#66d9ef">val</span> sc <span style="color:#66d9ef">:</span> <span style="color:#66d9ef">SparkContext</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">SparkContext</span><span style="color:#f92672">(</span>sparkConf<span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 读取文件数据
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> fileRDD<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;input/word.txt&#34;</span><span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 将文件中的数据进行分词
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> wordRDD<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> fileRDD<span style="color:#f92672">.</span>flatMap<span style="color:#f92672">(</span> <span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">)</span> <span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 转换数据结构 word =&gt; (word, 1)
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> word2OneRDD<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#f92672">(</span><span style="color:#66d9ef">String</span>, <span style="color:#66d9ef">Int</span><span style="color:#f92672">)</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> wordRDD<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span><span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">,</span><span style="color:#ae81ff">1</span><span style="color:#f92672">)</span><span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 将转换结构后的数据按照相同的单词进行分组聚合
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> word2CountRDD<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#f92672">(</span><span style="color:#66d9ef">String</span>, <span style="color:#66d9ef">Int</span><span style="color:#f92672">)</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> word2OneRDD<span style="color:#f92672">.</span>reduceByKey<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">+</span><span style="color:#66d9ef">_</span><span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 将数据聚合结果采集到内存中
</span><span style="color:#75715e"></span>  
<span style="color:#66d9ef">val</span> word2Count<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Array</span><span style="color:#f92672">[</span><span style="color:#f92672">(</span><span style="color:#66d9ef">String</span>, <span style="color:#66d9ef">Int</span><span style="color:#f92672">)</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> word2CountRDD<span style="color:#f92672">.</span>collect<span style="color:#f92672">(</span><span style="color:#f92672">)</span>
  
<span style="color:#75715e">// 打印结果
</span><span style="color:#75715e"></span>  
word2Count<span style="color:#f92672">.</span>foreach<span style="color:#f92672">(</span>println<span style="color:#f92672">)</span>
  
<span style="color:#75715e">//关闭 Spark 连接
</span><span style="color:#75715e"></span>  
sc<span style="color:#f92672">.</span>stop<span style="color:#f92672">(</span><span style="color:#f92672">)</span>
</code></pre></div></li>
<li>
<p>执行过程中，会产生大量的执行日志，如果为了能够更好的查看程序的执行结果，可以在项目的 resources 目录中创建log4j.properties 文件，并添加日志配置信息：</p>
<pre><code class="language-properties" data-lang="properties">log4j.rootCategory=ERROR, console
log4j.appender.console=org.apache.log4j.ConsoleAppender log4j.appender.console.target=System.err log4j.appender.console.layout=org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
  
# Set the default spark-shell log level to ERROR. When running the spark-shell, the
# log level for this class is used to overwrite the root logger's log level, so that
# the user can have different defaults for the shell and regular Spark apps. log4j.logger.org.apache.spark.repl.Main=ERROR
  
# Settings to quiet third party logs that are too verbose log4j.logger.org.spark_project.jetty=ERROR log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
  
# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
</code></pre></li>
<li>
<p>异常处理</p>
<p>如果本机操作系统是 Windows，在程序中使用了 Hadoop 相关的东西，比如写入文件到HDFS，则会遇到如下异常：</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4c36n10oj30ob05o41z.jpg" alt="QQ截图20211206192224.png"></p>
<p>出现这个问题的原因，并不是程序的错误，而是windows 系统用到了 hadoop 相关的服务，解决办法是通过配置关联到 windows 的系统依赖就可以了</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4c3feakij30o0090afe.jpg" alt="QQ截图20211206192305.png"></p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4c3lp7j3j30n90g2432.jpg" alt="QQ截图20211206192319.png"></p>
</li>
</ul>
<h2 id="spark-运行环境">Spark 运行环境</h2>
<ul>
<li>
<p>Spark 作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行, 在国内工作中主流的环境为Yarn，不过逐渐容器式环境也慢慢流行起来。</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4c4dxjwgj30et08t0vj.jpg" alt="QQ截图20211206192510.png"></p>
</li>
</ul>
<h3 id="local-模式">Local 模式</h3>
<ul>
<li>所谓的Local 模式，就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学，调试，演示等， 之前在 IDEA 中运行代码的环境我们称之为开发环境，不太一样。</li>
</ul>
<h4 id="解压缩文件">解压缩文件</h4>
<ul>
<li>
<p>将 spark-3.0.0-bin-hadoop3.2.tgz 文件上传到Linux 并解压缩，放置在指定位置，路径中不要包含中文或空格，课件后续如果涉及到解压缩操作，不再强调。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module 
cd /opt/module
mv spark-3.0.0-bin-hadoop3.2 spark-local
</code></pre></div></li>
</ul>
<h4 id="启动local环境">启动Local环境</h4>
<ul>
<li>
<p>进入解压缩后的路径，执行如下指令</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-shell
</code></pre></div></li>
<li>
<p>启动成功后，可以输入网址进行 Web UI 监控页面访问</p>
<pre><code>http://虚拟机地址:4040
</code></pre><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4ca0mw8kj30om04djsl.jpg" alt="QQ截图20211206193033.png"></p>
</li>
</ul>
<h4 id="命令行工具">命令行工具</h4>
<ul>
<li>
<p>在解压缩文件夹下的 data 目录中，添加 word.txt 文件。在命令行工具中执行如下代码指令（和 IDEA 中代码简化版一致）</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;data/word.txt&#34;</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>flatMap<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">)</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>map<span style="color:#f92672">(</span><span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">,</span><span style="color:#ae81ff">1</span><span style="color:#f92672">)</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>reduceByKey<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">+</span><span style="color:#66d9ef">_</span><span style="color:#f92672">)</span><span style="color:#f92672">.</span>collect
</code></pre></div><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cbg3x1jj30p101h75q.jpg" alt="QQ截图20211206193157.png"></p>
</li>
</ul>
<h4 id="退出本地模式">退出本地模式</h4>
<ul>
<li>
<p>按键 Ctrl+C 或输入 Scala 指令</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">:quit
</code></pre></div></li>
</ul>
<h4 id="提交应用">提交应用</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-submit <span style="color:#ae81ff">\</span>
--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\</span>
--master local<span style="color:#f92672">[</span>2<span style="color:#f92672">]</span> <span style="color:#ae81ff">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span style="color:#ae81ff">\</span>
10
</code></pre></div><ul>
<li>
<p>&ndash;class 表示要执行程序的主类，此处可以更换为咱们自己写的应用程序</p>
</li>
<li>
<p>&ndash;master local[2] 部署模式，默认为本地模式，数字表示分配的虚拟 CPU 核数量</p>
</li>
<li>
<p>spark-examples_2.12-3.0.0.jar 运行的应用类所在的 jar 包，实际使用时，可以设定为咱们自己打的 jar 包</p>
</li>
<li>
<p>数字 10 表示程序的入口参数，用于设定当前应用的任务数量</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cdv3vq0j30p808jn7q.jpg" alt="QQ截图20211206193415.png"></p>
</li>
</ul>
<h3 id="standalone-模式"><strong>Standalone</strong> 模式</h3>
<ul>
<li>
<p>只使用 Spark 自身节点运行的集群模式，也就是我们所谓的独立部署（Standalone）模式。Spark 的 Standalone 模式体现了经典的 master-slave 模式。集群规划:</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cg5x1afj30ox02edgj.jpg" alt="QQ截图20211206193629.png"></p>
</li>
</ul>
<h4 id="解压缩文件-1"><strong>解压缩文件</strong></h4>
<ul>
<li>
<p>将 spark-3.0.0-bin-hadoop3.2.tgz 文件上传到 Linux 并解压缩在指定位置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module
cd /opt/module 
mv spark-3.0.0-bin-hadoop3.2 spark-standalone
</code></pre></div></li>
</ul>
<h4 id="修改配置文件"><strong>修改配置文件</strong></h4>
<ul>
<li>
<p>进入解压缩后路径的 conf 目录，修改 slaves.template 文件名为 slaves</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mv slaves.template slaves
</code></pre></div></li>
<li>
<p>修改 slaves 文件，添加 work 节点</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">linux1
linux2
linux3
</code></pre></div></li>
<li>
<p>修改 spark-env.sh.template 文件名为 spark-env.sh</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mv spark-env.sh.template spark-env.sh
</code></pre></div></li>
<li>
<p>修改 spark-env.sh 文件，添加 JAVA_HOME 环境变量和集群对应的 master 节点</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">export JAVA_HOME<span style="color:#f92672">=</span>/opt/module/jdk1.8.0_144
SPARK_MASTER_HOST<span style="color:#f92672">=</span>linux1
SPARK_MASTER_PORT<span style="color:#f92672">=</span>7077
</code></pre></div><p><strong>注意：7077 端口，相当于 hadoop3 内部通信的 8020 端口，此处的端口需要确认自己的 Hadoop配置</strong></p>
</li>
<li>
<p>分发 spark-standalone 目录</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">xsync spark-standalone
</code></pre></div></li>
</ul>
<h4 id="启动集群"><strong>启动集群</strong></h4>
<ul>
<li>
<p>执行脚本命令：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sbin/start-all.sh
</code></pre></div><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4clg7tztj30p304h43b.jpg" alt="QQ截图20211206194133.png"></p>
</li>
<li>
<p>查看三台服务器运行进程</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>linux1<span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>
<span style="color:#ae81ff">3330</span> Jps
<span style="color:#ae81ff">3238</span> Worker
<span style="color:#ae81ff">3163</span> Master
<span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>linux2<span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>
<span style="color:#ae81ff">2966</span> Jps
<span style="color:#ae81ff">2908</span> Worker
<span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>linux3<span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span><span style="color:#f92672">=</span>
<span style="color:#ae81ff">2978</span> Worker
<span style="color:#ae81ff">3036</span> Jps
</code></pre></div></li>
<li>
<p>查看 Master 资源监控 Web UI 界面: http://linux1:8080</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cmoqqx8j30p90bdjvz.jpg" alt="QQ截图20211206194245.png"></p>
</li>
</ul>
<h4 id="提交应用-1"><strong>提交应用</strong></h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-submit <span style="color:#ae81ff">\</span>
--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\</span>
--master spark://linux1:7077 <span style="color:#ae81ff">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span style="color:#ae81ff">\</span>
10
</code></pre></div><ul>
<li>
<p>&ndash;class 表示要执行程序的主类</p>
</li>
<li>
<p>&ndash;master spark://linux1:7077 独立部署模式，连接到 Spark 集群</p>
</li>
<li>
<p>spark-examples_2.12-3.0.0.jar 运行类所在的 jar 包</p>
</li>
<li>
<p>数字 10 表示程序的入口参数，用于设定当前应用的任务数量</p>
</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4coigcmnj30pt0lc4fj.jpg" alt="QQ截图20211206194427.png"></p>
<h4 id="提交参数说明"><strong>提交参数说明</strong></h4>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cpjsf7cj30py0b1q8n.jpg" alt="QQ截图20211206194522.png"></p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cpph3pnj30ph03bjsi.jpg" alt="QQ截图20211206194530.png"></p>
<h4 id="配置历史服务"><strong>配置历史服务</strong></h4>
<ul>
<li>
<p>由于 spark-shell 停止掉后，集群监控 linux1:4040 页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况。</p>
</li>
<li>
<p>修改 spark-defaults.conf.template 文件名为 spark-defaults.conf</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mv spark-defaults.conf.template spark-defaults.conf
</code></pre></div></li>
<li>
<p>修改 spark-default.conf 文件，配置日志存储路径</p>
<pre><code>spark.eventLog.enabled true
spark.eventLog.dir hdfs://linux1:8020/directory
</code></pre><p>注意：需要启动 hadoop 集群，HDFS 上的 directory 目录需要提前存在。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sbin/start-dfs.sh
hadoop fs -mkdir /directory
</code></pre></div></li>
<li>
<p>修改 spark-env.sh 文件, 添加日志配置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">export SPARK_HISTORY_OPTS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;
</span><span style="color:#e6db74">-Dspark.history.ui.port=18080 
</span><span style="color:#e6db74">-Dspark.history.fs.logDirectory=hdfs://linux1:8020/directory 
</span><span style="color:#e6db74">-Dspark.history.retainedApplications=30&#34;</span>
</code></pre></div><p>参数 1 含义：WEB UI 访问的端口号为 18080</p>
<p>参数 2 含义：指定历史服务器日志存储路径</p>
<p>参数 3 含义：指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p>
</li>
<li>
<p>分发配置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">xsync conf
</code></pre></div></li>
<li>
<p>重新启动集群和历史服务</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sbin/start-all.sh
sbin/start-history-server.sh
</code></pre></div></li>
<li>
<p>重新执行任务</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-submit <span style="color:#ae81ff">\</span>
--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\</span>
--master spark://linux1:7077 <span style="color:#ae81ff">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span style="color:#ae81ff">\</span>
10
</code></pre></div><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cwr3l96j30pg08nk2f.jpg" alt="QQ截图20211206195225.png"></p>
</li>
<li>
<p>查看历史服务：http://linux1:18080</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4cxgosebj30ow05fac2.jpg" alt="QQ截图20211206195306.png"></p>
</li>
</ul>
<h4 id="配置高可用ha">配置高可用（HA）</h4>
<ul>
<li>
<p>所谓的高可用是因为当前集群中的 Master 节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个 Master 节点，一旦处于活动状态的 Master发生故障时，由备用 Master 提供服务，保证作业可以继续执行。这里的高可用一般采用Zookeeper 设置</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4d1q2o82j30pd05g400.jpg" alt="QQ截图20211206195709.png"></p>
<ul>
<li>
<p>停止集群</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sbin/stop-all.sh
</code></pre></div></li>
<li>
<p>启动 Zookeeper</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">xstart zk
</code></pre></div></li>
<li>
<p>修改 spark-env.sh 文件添加如下配置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">注释如下内容：
<span style="color:#75715e">#SPARK_MASTER_HOST=linux1</span>
<span style="color:#75715e">#SPARK_MASTER_PORT=7077</span>
添加如下内容:
<span style="color:#75715e">#Master 监控页面默认访问端口为 8080，但是可能会和 Zookeeper 冲突，所以改成 8989，也可以自定义，访问 UI 监控页面时请注意</span>
SPARK_MASTER_WEBUI_PORT<span style="color:#f92672">=</span>8989
export SPARK_DAEMON_JAVA_OPTS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;
</span><span style="color:#e6db74">-Dspark.deploy.recoveryMode=ZOOKEEPER 
</span><span style="color:#e6db74">-Dspark.deploy.zookeeper.url=linux1,linux2,linux3
</span><span style="color:#e6db74">-Dspark.deploy.zookeeper.dir=/spark&#34;</span>
</code></pre></div></li>
<li>
<p>分发配置文件</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">xsync conf/
</code></pre></div></li>
<li>
<p>启动集群</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sbin/start-all.sh
</code></pre></div></li>
<li>
<p>启动 linux2 的单独 Master 节点，此时 linux2 节点 Master 状态处于备用状态</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#f92672">[</span>root@linux2 spark-standalone<span style="color:#f92672">]</span><span style="color:#75715e"># sbin/start-master.sh</span>
</code></pre></div><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4d53i00vj30pt099q61.jpg" alt="QQ截图20211206200027.png"></p>
</li>
<li>
<p>提交应用到高可用集群</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-submit <span style="color:#ae81ff">\</span>
--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\</span>
--master spark://linux1:7077,linux2:7077 <span style="color:#ae81ff">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span style="color:#ae81ff">\</span>
10
</code></pre></div></li>
<li>
<p>停止 linux1 的 Master 资源监控进程</p>
</li>
<li>
<p>查看 linux2 的 Master 资源监控 Web UI，稍等一段时间后，linux2 节点的 Master 状态提升为活动状态</p>
</li>
</ul>
</li>
</ul>
<h3 id="yarn-模式"><strong>Yarn</strong> 模式</h3>
<ul>
<li>
<p>独立部署（Standalone）模式由 Spark 自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark 主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。</p>
</li>
<li>
<p><strong>解压缩文件</strong></p>
<ul>
<li>
<p>将 spark-3.0.0-bin-hadoop3.2.tgz 文件上传到 linux 并解压缩，放置在指定位置。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module
cd /opt/module 
mv spark-3.0.0-bin-hadoop3.2 spark-yarn
</code></pre></div></li>
</ul>
</li>
<li>
<p><strong>修改配置文件</strong></p>
<ul>
<li>
<p>修改 hadoop 配置文件/opt/module/hadoop/etc/hadoop/yarn-site.xml, 并分发</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#75715e">&lt;!--</span><span style="color:#75715e">是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是 true </span><span style="color:#75715e">--&gt;</span>
<span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
   <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.nodemanager.pmem-check-enabled<span style="color:#f92672">&lt;/name&gt;</span>
   <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>false<span style="color:#f92672">&lt;/value&gt;</span>
<span style="color:#f92672">&lt;/property&gt;</span>
<span style="color:#75715e">&lt;!--</span><span style="color:#75715e">是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是 true </span><span style="color:#75715e">--&gt;</span>
<span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
   <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.nodemanager.vmem-check-enabled<span style="color:#f92672">&lt;/name&gt;</span>
   <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>false<span style="color:#f92672">&lt;/value&gt;</span>
<span style="color:#f92672">&lt;/property&gt;</span>
</code></pre></div></li>
<li>
<p>修改 conf/spark-env.sh，添加 JAVA_HOME 和 YARN_CONF_DIR 配置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mv spark-env.sh.template spark-env.sh
。。。
export JAVA_HOME<span style="color:#f92672">=</span>/opt/module/jdk1.8.0_144
YARN_CONF_DIR<span style="color:#f92672">=</span>/opt/module/hadoop/etc/hadoop
</code></pre></div></li>
</ul>
</li>
<li>
<p><strong>启动</strong> <strong>HDFS</strong> <strong>以及</strong> <strong>YARN</strong> <strong>集群</strong></p>
</li>
<li>
<p><strong>提交应用</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">bin/spark-submit <span style="color:#ae81ff">\</span>
--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\</span>
--master yarn <span style="color:#ae81ff">\</span>
--deploy-mode cluster <span style="color:#ae81ff">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span style="color:#ae81ff">\</span>
10
</code></pre></div><p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4dcuwp94j30q80mp4g6.jpg" alt="QQ截图20211206200745.png"></p>
</li>
</ul>
<h3 id="部署模式对比"><strong>部署模式对比</strong></h3>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4dfp88xpj30pb04hmzb.jpg" alt="QQ截图20211206201037.png"></p>
<h3 id="端口号">端口号</h3>
<ul>
<li>Spark 查看当前 Spark-shell 运行任务情况端口号：4040（计算）</li>
<li>Spark Master 内部通信服务端口号：7077</li>
<li>Standalone 模式下，Spark Master Web 端口号：8080（资源）</li>
<li>Spark 历史服务器端口号：18080</li>
<li>Hadoop YARN 任务运行情况查看端口号：8088</li>
</ul>
<h2 id="spark运行架构"><strong>Spark</strong>运行架构</h2>
<h3 id="运行架构"><strong>运行架构</strong></h3>
<ul>
<li>
<p>Spark 框架的核心是一个计算引擎，整体来说，它采用了标准 master-slave 的结构。</p>
</li>
<li>
<p>如下图所示，它展示了一个 Spark 执行时的基本结构。图形中的 Driver 表示 master，负责管理整个集群中的作业任务调度。图形中的 Executor 则是 slave，负责实际执行任务。</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4dhomv3uj30kx07rmyi.jpg" alt="QQ截图20211206201233.png"></p>
</li>
</ul>
<h3 id="核心组件"><strong>核心组件</strong></h3>
<ul>
<li>由上图可以看出，对于 Spark 框架有两个核心组件：</li>
</ul>
<h4 id="driver">Driver</h4>
<ul>
<li>
<p>Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行工作。Driver 在 Spark 作业执行时主要负责：</p>
<ul>
<li>
<p>将用户程序转化为作业（job）</p>
</li>
<li>
<p>在 Executor 之间调度任务(task)</p>
</li>
<li>
<p>跟踪 Executor 的执行情况</p>
</li>
<li>
<p>通过 UI 展示查询运行情况</p>
</li>
</ul>
</li>
<li>
<p>实际上，我们无法准确地描述 Driver 的定义，因为在整个的编程过程中没有看到任何有关Driver 的字眼。所以简单理解，所谓的 Driver 就是驱使整个应用运行起来的程序，也称之为Driver 类。</p>
</li>
</ul>
<h4 id="executor"><strong>Executor</strong></h4>
<ul>
<li>
<p>Spark Executor 是集群中工作节点（Worker）中的一个 JVM 进程，负责在 Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有 Executor 节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他 Executor 节点上继续运行。</p>
</li>
<li>
<p>Executor 有两个核心功能：</p>
<ul>
<li>负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程</li>
<li>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在 Executor 进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</li>
</ul>
</li>
</ul>
<h4 id="master--worker"><strong>Master &amp; Worker</strong></h4>
<ul>
<li>Spark 集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能，所以环境中还有其他两个核心组件：Master 和 Worker，这里的 Master 是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责，类似于 Yarn 环境中的 RM, 而Worker 呢，也是进程，一个 Worker 运行在集群中的一台服务器上，由 Master 分配资源对数据进行并行的处理和计算，类似于 Yarn 环境中 NM。</li>
</ul>
<h4 id="applicationmaster">ApplicationMaster</h4>
<ul>
<li>Hadoop 用户向 YARN 集群提交应用程序时,提交程序中应该包含ApplicationMaster，用于向资源调度器申请执行任务的资源容器 Container，运行用户自己的程序任务 job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。</li>
<li>说的简单点就是，ResourceManager（资源）和Driver（计算）之间的解耦合靠的就是ApplicationMaster。</li>
</ul>
<h3 id="核心概念">核心概念</h3>
<h4 id="executor-与-core">Executor 与 Core</h4>
<ul>
<li>
<p>Spark Executor 是集群中运行在工作节点（Worker）中的一个 JVM 进程，是整个集群中的专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点 Executor 的内存大小和使用的虚拟 CPU 核（Core）数量。</p>
</li>
<li>
<p>应用程序相关启动参数如下：</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4e4woj09j30ok04umyv.jpg" alt="QQ截图20211206203451.png"></p>
</li>
</ul>
<h4 id="并行度parallelism">并行度（Parallelism）</h4>
<ul>
<li>将整个集群并行执行任务的数量称之为并行度</li>
</ul>
<h4 id="有向无环图dag">有向无环图（DAG）</h4>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4e6pq872j30fu079gmb.jpg" alt="QQ截图20211206203636.png"></p>
<ul>
<li>
<p>大数据计算引擎框架我们根据使用方式的不同一般会分为四类，其中第一类就是Hadoop 所承载的 MapReduce,它将计算分为两个阶段，分别为 Map 阶段 和 Reduce 阶段。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个 Job 的串联，以完成一个完整的算法，例如迭代计算。 由于这样的弊端，催生了支持 DAG 框架的产生。因此，支持 DAG 的框架被划分为第二代计算引擎。如 Tez 以及更上层的Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，大多还是批处理的任务。接下来就是以 Spark 为代表的第三代的计算引擎。第三代计算引擎的特点主要是 Job 内部的 DAG 支持（不跨越 Job），以及实时计算。</p>
</li>
<li>
<p>这里所谓的有向无环图，并不是真正意义的图形，而是由 Spark 程序直接映射成的数据流的高级抽象模型。简单理解就是将整个程序计算的执行过程用图形表示出来,这样更直观， 更便于理解，可以用于表示程序的拓扑结构。</p>
</li>
<li>
<p>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。</p>
</li>
</ul>
<h3 id="提交流程">提交流程</h3>
<ul>
<li>
<p>所谓的提交流程，其实就是我们开发人员根据需求写的应用程序通过 Spark 客户端提交给 Spark 运行环境执行计算的流程。在不同的部署环境中，这个提交过程基本相同，但是又有细微的区别，我们这里不进行详细的比较，但是因为国内工作中，将 Spark 引用部署到Yarn 环境中会更多一些，所以本课程中的提交流程是基于 Yarn 环境的。</p>
<p><img src="http://ww1.sinaimg.cn/large/006QQPIfly1gx4e8t1ifmj30n10cgabp.jpg" alt="QQ截图20211206203833.png"></p>
</li>
<li>
<p>Spark 应用程序提交到 Yarn 环境中执行的时候，一般会有两种部署执行的方式：Client 和 Cluster。<strong>两种模式主要区别在于：Driver 程序的运行节点位置。</strong></p>
</li>
</ul>
<h4 id="yarn-client-模式">Yarn Client 模式</h4>
<ul>
<li>Client 模式将用于监控和调度的Driver 模块在客户端执行，而不是在 Yarn 中，所以一般用于测试。
<ul>
<li>Driver 在任务提交的本地机器上运行</li>
<li>Driver 启动后会和ResourceManager 通讯申请启动ApplicationMaster</li>
<li>ResourceManager 分配 container，在合适的NodeManager 上启动ApplicationMaster，负责向ResourceManager 申请 Executor 内存</li>
<li>ResourceManager 接到 ApplicationMaster 的资源申请后会分配 container，然后ApplicationMaster 在资源分配指定的NodeManager 上启动 Executor 进程</li>
<li>Executor 进程启动后会向Driver 反向注册，Executor 全部注册完成后Driver 开始执行main 函数</li>
<li>之后执行到 Action 算子时，触发一个 Job，并根据宽依赖开始划分 stage，每个stage 生成对应的TaskSet，之后将 task 分发到各个Executor 上执行。</li>
</ul>
</li>
</ul>
<h4 id="yarn-cluster-模式"><strong>Yarn</strong> <strong>Cluster</strong> 模式</h4>
<ul>
<li>Cluster 模式将用于监控和调度的 Driver 模块启动在Yarn 集群资源中执行。一般应用于实际生产环境。
<ul>
<li>在 YARN Cluster 模式下，任务提交后会和ResourceManager 通讯申请启动ApplicationMaster</li>
<li>随后ResourceManager 分配 container，在合适的 NodeManager 上启动 ApplicationMaster，此时的 ApplicationMaster 就是Driver。</li>
<li>Driver 启动后向 ResourceManager 申请Executor 内存，ResourceManager 接到ApplicationMaster 的资源申请后会分配container，然后在合适的NodeManager 上启动Executor 进程</li>
<li>Executor 进程启动后会向Driver 反向注册，Executor 全部注册完成后Driver 开始执行main 函数</li>
<li>之后执行到 Action 算子时，触发一个 Job，并根据宽依赖开始划分 stage，每个stage 生成对应的TaskSet，之后将 task 分发到各个Executor 上执行。</li>
</ul>
</li>
</ul>


                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/910completablefuture/" data-toggle="tooltip" data-placement="top" title="11、CompletableFuture（JUC）">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/942sparkcore%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/" data-toggle="tooltip" data-placement="top" title="2、SparkCore核心编程（Spark）">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>

                
<div id="disqus-comment"></div>



            </div>
            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">标签</a></h5>
                    <div class="tags">
                        
                        
                        
                        <a href="/tags/activemq" title="activemq">
                            activemq
                        </a>
                        
                        
                        
                        <a href="/tags/ajax" title="ajax">
                            ajax
                        </a>
                        
                        
                        
                        <a href="/tags/cookie" title="cookie">
                            cookie
                        </a>
                        
                        
                        
                        <a href="/tags/datax" title="datax">
                            datax
                        </a>
                        
                        
                        
                        <a href="/tags/docker" title="docker">
                            docker
                        </a>
                        
                        
                        
                        <a href="/tags/filter" title="filter">
                            filter
                        </a>
                        
                        
                        
                        <a href="/tags/hadoop" title="hadoop">
                            hadoop
                        </a>
                        
                        
                        
                        <a href="/tags/hbase" title="hbase">
                            hbase
                        </a>
                        
                        
                        
                        <a href="/tags/hive" title="hive">
                            hive
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/java" title="java">
                            java
                        </a>
                        
                        
                        
                        <a href="/tags/javascript" title="javascript">
                            javascript
                        </a>
                        
                        
                        
                        <a href="/tags/javaweb" title="javaweb">
                            javaweb
                        </a>
                        
                        
                        
                        <a href="/tags/jdbc" title="jdbc">
                            jdbc
                        </a>
                        
                        
                        
                        <a href="/tags/jquery" title="jquery">
                            jquery
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/jsp" title="jsp">
                            jsp
                        </a>
                        
                        
                        
                        <a href="/tags/juc" title="juc">
                            juc
                        </a>
                        
                        
                        
                        <a href="/tags/jwt" title="jwt">
                            jwt
                        </a>
                        
                        
                        
                        <a href="/tags/kafka" title="kafka">
                            kafka
                        </a>
                        
                        
                        
                        <a href="/tags/linux" title="linux">
                            linux
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/maven" title="maven">
                            maven
                        </a>
                        
                        
                        
                        <a href="/tags/minio" title="minio">
                            minio
                        </a>
                        
                        
                        
                        <a href="/tags/mongodb" title="mongodb">
                            mongodb
                        </a>
                        
                        
                        
                        <a href="/tags/mybatis" title="mybatis">
                            mybatis
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/mysql" title="mysql">
                            mysql
                        </a>
                        
                        
                        
                        <a href="/tags/netty" title="netty">
                            netty
                        </a>
                        
                        
                        
                        <a href="/tags/nginx" title="nginx">
                            nginx
                        </a>
                        
                        
                        
                        <a href="/tags/react" title="react">
                            react
                        </a>
                        
                        
                        
                        <a href="/tags/redis" title="redis">
                            redis
                        </a>
                        
                        
                        
                        <a href="/tags/scala" title="scala">
                            scala
                        </a>
                        
                        
                        
                        <a href="/tags/servlet" title="servlet">
                            servlet
                        </a>
                        
                        
                        
                        <a href="/tags/session" title="session">
                            session
                        </a>
                        
                        
                        
                        <a href="/tags/shiro" title="shiro">
                            shiro
                        </a>
                        
                        
                        
                        <a href="/tags/spark" title="spark">
                            spark
                        </a>
                        
                        
                        
                        <a href="/tags/spring" title="spring">
                            spring
                        </a>
                        
                        
                        
                        <a href="/tags/springboot" title="springboot">
                            springboot
                        </a>
                        
                        
                        
                        <a href="/tags/springcloud" title="springcloud">
                            springcloud
                        </a>
                        
                        
                        
                        <a href="/tags/springmvc" title="springmvc">
                            springmvc
                        </a>
                        
                        
                        
                        <a href="/tags/springsecurity" title="springsecurity">
                            springsecurity
                        </a>
                        
                        
                        
                        <a href="/tags/tomcat" title="tomcat">
                            tomcat
                        </a>
                        
                        
                        
                        <a href="/tags/vue" title="vue">
                            vue
                        </a>
                        
                        
                        
                        <a href="/tags/xml" title="xml">
                            xml
                        </a>
                        
                        
                        
                        <a href="/tags/zookeeper" title="zookeeper">
                            zookeeper
                        </a>
                        
                        
                        
                        <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95" title="数据结构与算法">
                            数据结构与算法
                        </a>
                        
                        
                        
                        <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F" title="设计模式">
                            设计模式
                        </a>
                        
                        
                        
                        <a href="/tags/%E9%A1%B9%E7%9B%AE" title="项目">
                            项目
                        </a>
                        
                        
                    </div>
                </section>
                

                
                
                <section>
                    <hr>
                    <h5>朋友</h5>
                    <ul class="list-inline">
                        
                        <li><a target="_blank" href=""></a></li>
                        
                    </ul>
                </section>
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                 
                   
                    
                    <li>
                        <a href="mailto:1424197205@qq.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    

                    

		    
                    
                    <li>
                        <a target="_blank" href="#">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-wechat fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    <li>
                        <a target="_blank" href="https://github.com/yiguan1573">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    
                    
                    
                    
                    
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; 亿观的博客 2022
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>






</body>
</html>
